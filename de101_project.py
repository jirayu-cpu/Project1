# -*- coding: utf-8 -*-
"""DE101 Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s6eYcKztu14Lof4PQBwRK6VNbWVMe1dB

**ติดตั้ง Spark และ PySpark**
"""

!apt-get update                                                                          # อัพเดท Package ทั้งหมดใน VM ตัวนี้
!apt-get install openjdk-8-jdk-headless -qq > /dev/null                                  # ติดตั้ง Java Development Kit (จำเป็นสำหรับการติดตั้ง Spark)
!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz # ติดตั้ง Spark 3.1.2
!tar xzvf spark-3.1.2-bin-hadoop2.7.tgz                                                  # Unzip ไฟล์ Spark 3.1.2
!pip install -q findspark==1.3.0                                                         # ติดตั้ง Package Python สำหรับเชื่อมต่อกับ Spark

"""**Set enviroment variable ให้ Python รู้จัก Spark**

"""

import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.1.2-bin-hadoop2.7"

"""**ติดตั้ง PySpark ลงใน Python**"""

!pip install pyspark==3.1.2

"""**สร้าง Spark Session เพิ้อใช้งาน Spark**"""

from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[*]").getOrCreate()

"""**Load data ใส่ Spark**"""

dt = spark.read.csv("/content/sample_data/salaries-by-college-type.csv", header = True)

"""## **Data Profiling**"""

dt.columns

dt.printSchema()

dt.dtypes

dt.show(10)

print(dt.count(), len(dt.columns))

"""**Statistic Summary**"""

dt.describe().show()

dt.summary().show()

dt.select("Mid-Career Median Salary").describe().show()

from pyspark.sql.functions import col, regexp_replace

for c in dt.columns :
  dt = dt.withColumn(c, regexp_replace(col(c), "\\$", ""))

dt.show()

for c in dt.columns[2:] :
  dt = dt.withColumn(c, regexp_replace(col(c), "\\,", ""))

dt.show()

import pyspark.sql.functions as F
for c in dt.columns[2:] :

  dt = dt.withColumn(c, F.col(c).cast("float"))

dt.dtypes

"""## **EDA - Exploratory Data Analysis**"""

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

dt_pd = dt.toPandas()

dt_pd.head()

dt_pd = dt_pd.replace("NaA", float("nan"))

column_averages = dt_pd.iloc[:, 2:].mean()

for c in dt_pd.columns[2:]:
    dt_pd[c] = dt_pd[c].fillna(column_averages[c])

dt_pd.head()

"""**Box Plot**"""

selected_columns = dt_pd.columns[2:]

for c in selected_columns:
    sns.boxplot(x=c, data=dt_pd)
    plt.title(f"Box plot for {c}")
    plt.show()

"""**Violin Plot**"""

for c in selected_columns:
    sns.violinplot(x=c, data=dt_pd)
    plt.title(f"Violin plot for {c}")
    plt.show()

"""**Scatter Plot**"""

sns.scatterplot(x=dt_pd["School Type"], y=dt_pd["Starting Median Salary"])

"""**Interact Chart**"""

import plotly.express as px

fig = px.scatter(dt_pd, 'School Type', 'Starting Median Salary')
fig.show()

"""# **Data Cleansing with Spark**"""

dt.show(truncate=False)

dt.printSchema()

"""**Check Value correction**"""

for c in dt.columns[:2] :

  dt.select(c).distinct().sort(c).show(truncate = False)

"""**Check Null Value**"""

dt.where(dt["Mid-Career 10th Percentile Salary"].isNull()).show()

"""**Replace Null Value with Average**"""

for c in dt.columns[3:]:

  avg_salary = dt.agg(F.avg(c)).collect()[0][0]

  dt = dt.withColumn(c, F.when(dt[c].isNull(), avg_salary).otherwise(dt[c]))

dt.show()

"""# **Spark SQL**"""

dt.createOrReplaceTempView("data")
dt_sql = spark.sql("SELECT * FROM data")
dt_sql.show()

dt_sql_school_type = spark.sql("""
SELECT distinct `School Type`
FROM data
ORDER BY `School Type`
""")
dt_sql_school_type.show(100)

"""**Group By**"""

dt_sql_school_type = spark.sql("""
SELECT `School Name`, `School Type`, AVG(`Starting Median Salary`) AS `Average Starting Median Salary`
FROM data
GROUP BY `School Name`, `School Type`
""")

dt_sql_school_type.show(100)

"""**Save Data**"""

dt.write.csv('Cleaned_data.csv', header = True)

"""**How to read multiple path**"""

#all_parts = spark.read.csv('/content/Cleaned_data.csv/part-*.csv', header = True, inferSchema = True)